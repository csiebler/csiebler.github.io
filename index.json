[{"content":"Hello world,\nSome of you have been coming to this website to find help for Azure-related questions that weren\u0026rsquo;t answered anywhere else on the web. Unfortunatly, most of this information is gone for good:\nAs some of you know, I\u0026rsquo;ve recently became a dad and my life turned upside down. For the past years, I\u0026rsquo;ve been hosting my former Wordpress site on a SaaS offering. Since it was prepaid for several years, I didn\u0026rsquo;t worry too much about it and kept writing posts. However, just as our baby was born the new billing cycle started - but it was not setup to auto-renew. Since I was not actively using the original email account any more that I\u0026rsquo;ve signed up with for the hosting, I forgot about it\u0026hellip;and so it happened that I missed the renewal period, and my account was eventually deleted. Lesson learned, back to GitHub Pages!\nI am hoping to re-write some of the most important posts over the coming weeks, if you have post suggestions, please reach out to me via LinkedIn.\nThanks, Clemens\n","date":"16 October 2022","permalink":"/posts/a-fresh-start/","section":"Posts","summary":"Hello world,","title":"A Fresh Start"},{"content":"","date":"16 October 2022","permalink":"/","section":"Clemens Siebler's Blog","summary":"","title":"Clemens Siebler's Blog"},{"content":"","date":"16 October 2022","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"Introduction # This post discusses how Cognitive Services can be used to process data that is securely stored behind a VNET. This allows to improve security further when processing sensitive data that is stored in Storage Accounts. In this post, we’ll look into using Read API (from the Azure Computer Vision API) to analyze documents that are heavily protected using networking rules.\nThis post also applies to other Cognitive Services, such as for example Form Recognizer or Speech API.\nData behind VNET – what does it mean? # In Azure, many users protect their data using a set of security perimeters. While these are typically not all measurements users take to store their data securely, those are the most common ones that most people use:\nAuthentication layer – requirement to authenticate at the storage layer, e.g., via a access key or based on an identity (could be a real user or a system managed identity) Authorization layer – what is the identity allowed to do with the data (just read certain folders, write data, delete, etc.) Networking layer – from where is the identity allowed to access the data (from the internet, from a range of IP addresses, only from within a VNET, from “nowhere”) For example, your Networking settings on your Storage Account might look like this: Typical Networking settings on a Storage Account In this case, the data can only be access, when the access request originates from within subnet default inside the VNET vnet-test.\nUsing these security measurements makes it incredibly hard/potentially impossible to have an attacker access the data. But this also creates a problem: what if an Azure service, like for example a Cognitive Service needs to access this data? The service might be authenticated (e.g., using a SAS URL), but from a networking perspective, the service is obviously not coming from within your VNET:\nRead API can\u0026rsquo;t access the storage In the drawing above the Read API is:\nAuthenticated to access the Storage Account and read the data (using the SAS URL from the request) Blocked by the networking rules of the Storage account If we would remove the networking rule on the storage account, the data access would obviously be allowed:\nRead API can access the storage However, this is obviously not the desired setup as the Storage Account might hold sensitive data.\nDesired state # Obviously, we want to make sure that we do everything possible to protect our data as much as we can. Furthermore, it would also be even more secure if we did not have to use a SAS URL at all. Sure, this URL might be short lived, but why not get rid of it if we can? But most importantly, we want to make sure we can use our Cognitive Services, despite the data being sitting behind a VNET.\nThe solution – Managed Identity and Resource Service Instances to the rescue! # The solution to make this scenario work requires two components:\nManaged Identities Resource Service Instances Managed Identities # Most Azure services can \u0026ldquo;assume\u0026rdquo; a Managed Identity. A Managed Identity is a system user that is tied to that specific Azure resource. Since it is a “user”, the identity lives in your Azure Active Directory. That means we can assign that identity other privileges, such as access to storage or other Azure services. This means we can firstly assign our Cognitive Service a Managed Identity. Secondly, we can allow that identity to be able to read/write to our storage account using IAM. As a result, the Cognitive Service can access data without the need for access keys. Instead, it automatically requests an OAuth token from AAD and uses it to authenticate to the storage.\nResource Service Instances # However, the networking layer will still block the request and this is where Resource Service Instances come into play. With this feature we can specify a list of Azure services that are allowed to connect to the storage account regardless of its networking settings. This means, we can explicitly permit our Cognitive Service resource to “tunnel through” the firewall. Is this a security issue? No, because it is only allowed for the identity of the Cognitive Service itself. And as this identity is a system user, it is automatically secured.\nOverall Architecture # Putting both together, we get to this:\nRead API can access the storage account using its Managed Identity In this case:\nRead API uses its Managed Identity to authenticate at the Storage Account (no SAS URL required!) The Resource Service Instance configuration on the Storage Account allows the Managed Identity to \u0026ldquo;get through\u0026rdquo; the VNET-firewall Step-by-step guide # To try this out, first create a new Computer Vision API (this includes the Read API):\nCreate a new Computer Vision API During the creation, make sure to enable Managed Identity. You can also always later enable it under the Identity tab:\nManaged Identity on Computer Vision API Next, click Azure Role Assignments on the same screen and select Add role assignment. Then, assign the Storage Blob Data Reader role to your Storage Account. Once done, you could send plain storage URLS without SAS tokens to Read API and it could read the data.\nNext, navigate to your Storage Account, select Networking and check the network settings. In our example here, we only allow access from selected networks. Ironically, we did not select any VNET, so the data can’t be accessed from anywhere, including Cognitive Services. However, we’ll add the Cognitive Services Resource type and then name of our Cognitive Service instance. This means our Cognitive Service can tunnel through this super-restrictive networking setting!\nAllowing our Cognitive Service resource to tunnel through the firewall Don\u0026rsquo;t forget to hit the save button.\nTesting the whole setup # Once done, we can fire a few REST API calls to send a document to the Read API:\n# @name read_document POST https://computer-vision-demo124.cognitiveservices.azure.com/vision/v3.2/read/analyze ?language=en \u0026amp;pages=1 \u0026amp;readingOrder=natural Content-Type: application/json Ocp-Apim-Subscription-Key: \u0026lt;secret key\u0026gt; { \u0026#34;url\u0026#34;: \u0026#34;https://dgjt35hksss.blob.core.windows.net/data/description.png\u0026#34; } ##### This request queries the status of the Read API operation # @name get_results GET {{read_document.response.headers.Operation-Location}} Content-Type: application/json Ocp-Apim-Subscription-Key: \u0026lt;secret key\u0026gt; The result looks successful:\n{ \u0026#34;status\u0026#34;: \u0026#34;succeeded\u0026#34;, \u0026#34;createdDateTime\u0026#34;: \u0026#34;2022-02-22T12:52:59Z\u0026#34;, \u0026#34;lastUpdatedDateTime\u0026#34;: \u0026#34;2022-02-22T12:53:00Z\u0026#34;, \u0026#34;analyzeResult\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;3.2.0\u0026#34;, \u0026#34;modelVersion\u0026#34;: \u0026#34;2021-04-12\u0026#34;, \u0026#34;readResults\u0026#34;: [ { \u0026#34;page\u0026#34;: 1, \u0026#34;angle\u0026#34;: -0.7095, ... Despite us just sending a regular URL (https://dgjt35hksss.blob.core.windows.net/data/description.png), the Read API can access the data:\nAuthenticated through its Managed Identity and allowed through the firewall by the Resource Instance configuration If we remove the Resource instance definition, we would get the following message, as the URL would return a 403 error to the Cognitive Service:\n{ \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;InvalidImageURL\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Failed to download the image from the submitted URL. The URL may either be invalid or the server hosting the image is experiencing some technical difficulties.\u0026#34; } } Great, looks like it is working fine now!\nBy the way, we can entirely avoid the secret to call the Cognitive Service itself. If you are interested, have a look at this blog post: Azure Active Directory (AAD) authentication for Azure Cognitive Services.\nSummary # Many users want to protect their sensitive data using as many measurements there are available on the Azure platform:\nFirstly, this will be using authentication and authorization for accessing data on storage Secondly, this will include networking rules to limit from where data can be accessed This creates a unique challenge for accessing this VNET-protected data using Cognitive Services. However, combing the usage of Managed Identities and Resource Service Instances solve the problem. They enable users to keep their data well protected, but still allows them to process it by Cognitive Services.\n","date":"22 February 2022","permalink":"/posts/using-cognitive-services-read-api-with-data-secured-by-vnet/","section":"Posts","summary":"Introduction # This post discusses how Cognitive Services can be used to process data that is securely stored behind a VNET.","title":"Using Cognitive Services Read API with data secured by VNET"},{"content":"Introduction # The Azure Read API allows you to perform OCR on scanned documents of all kinds. This is great for digitalizing contracts, books, or research documents. With support for features like natural reading order support, it can be used for a wide range of tasks.\nHowever, how we can use Azure Read API for processing many documents at scale? Let’s say we need to run 100000 documents through Read API. What is the quickest way that we can do it? What image resolution should we use? What are the tradeoffs we need to consider?\nIn this post, we’ll look at all these questions and discuss how things like image resolution and parallel processing affect the overall processing time for large OCR jobs.\nAzure Read API example document Image resolution # Let’s first evaluate if the image resolution makes a difference in terms of processing time and accuracy. For comparing recognition results, we will use the Levenshtein distance to measure the distance between the ground truth of the document and the Read API results.\nImage resolution Image size Processing time Levenshtein distance 500×667 100KB 1.2s 11 1000×1333 300KB 1.5s 6 2000×2667 1.3MB 1.7s 3 3000×4000 3.1MB 1.9s 0 A few things come to mind when looking at these numbers:\nLarger image resolution gives better results. We can see that Levenshtein distance drops with larger image size, and that is typically the main thing we’ll care about for OCR: the most accuracy recognition results. Azure Read API does not charge extra for larger images, so why not leverage this? Larger image resolution only minorly affects processing time. Despite increasing the total pixel count by 35x, processing time increased only by around 1.5x. We do not know for sure, but the Read API most likely performs some image auto-scaling before processing the document. As a first learning, we should rather use high-resolution images as Read API will produce better OCR results, does not take significantly longer, and most importantly, does not cost more! Next, let’s look at optimizing the overall processing time.\nOptimizing processing time # When calling the Read API, we first have to call the analyze API and then subsequently the analyzeResults API to fetch the results. Obviously, processing will happen in between these two calls. But is there anything else? While we do not know for certain, most likely the following two steps will happen in the backend:\nUpon calling analyze, our request is first put into a queue (service-side) An idle worker will fetch our request from the queue an process it Upon calling analyzeResults, the cached results will be returned to us Again, this is speculation and might not happen exactly like this in reality, but one way or the other, it is very likely that there will be some form of queueing happening. Once unqueued, one of the many workers will process it. Having that said, what is the best strategy to use when having to run OCR on many documents?\nTo find it out, let’s compare three strategies:\nOption 1 – Sequential: Process each document from start to finish in a gigantic for-loop Option 2 – Optimized: First call analyze for a mini-batch of documents in a for-loop (e.g., 100), then start calling analyzeResults for the mini-batch in a for-loop Option 3 – Multithreading: Run multiple threads, each thread processes one document from start to finish Intuitively, we’d suspect that option 3 would be the fastest, followed by option 2, and option 1 should be the slowest. Let’s see if this is actually true!\nFor testing this, we run the test code from a VM in Azure in the same region as the Read API endpoint. Test documents are stored on Azure Blob in the same region. As Read API is limited to 10 TPS (transactions per second) per default, we add sleep() statement the code to obey that limit. However, this limit can be increased through a support request or alternatively, we could just provision multiple Read API resources. For the multi-threaded test, we run 10 threads in parallel, each sequentially processing 10 documents using its own Cognitive Services resource (=total of 100 TPS).\nLet’s look at the results for processing 100 documents in various sizes with the three different approaches:\nProcessing times for 100 documents compared These results look not fully what we expected, so let’s discuss them:\nSame as in our prior tests, image size does not affect processing time in a significant way – everything is within the same ballpark. Sequential execution is the slowest. This was expected, as waiting for each document to finish before moving on does not take advantage of the parallel backend of the Read API. Furthermore, we might get a “disadvantageous\u0026quot; position in the queue for each new document. Option 2 seems to be the quickest. This seems reasonable, as by starting all analyze calls in one batch, we hopefully will get approximately very similar positions in the queue. Once we start querying for the results, most of them will be finished as they have been processed in parallel by the backend. This results in the overall lowest processing time. Using a multi-threaded approach (option 3) did not perform as fast as expected. This is most likely because each thread will process documents one by one. This will result in \u0026ldquo;disadvantageous\u0026rdquo; positions in the queue, which makes it inferior to option 2. There is some variance in execution time. For option 3, we can see that one of the documents properly got a very deep position in the queue, therefore increasing overall processing time significantly. Let’s look at the average processing time per document:\nAverage processing time per image Again, these results look a bit different to what we’ve probably expected:\nThere is a large inconstancy in the average processing time. For option 1 and option 3, we should see comparable numbers, but it looks like when the tests for option 3 were executed, the queues was “more busy\u0026quot; than during the first test. Average processing time for option 2 is obviously much slower. This seems weird, as we expect a FIFO approach by Read API, but it could have been that a document or analyzeResult request \u0026ldquo;got stuck\u0026rdquo;, hence blocking the for-loop. When it comes to learnings, we can see that using an optimized sequential approach where we decouple the analyze and analyzeResult calls provides the overall quickest processing times.\nSummary # When using Azure Read API for processing many documents at scale (e.g., 1000’s, 10k’s or even 100k’s of documents), it makes sense to figure out a good strategy for processing them in parallel. In this post, we figured out a few highlights, so let’s summarize them:\nUse the highest available image resolution available. This will provide better recognition results, won’t cost more, and only takes slightly longer. Do not process files sequentially, as this does not take advantage of the parallel backend of the Read API. For quickest processing time, start calling the analyze API with a large mini-batch (e.g., 100 documents), then query the results using analyzeResults for the mini-batch in a for-loop. This is a simple strategy, allows for easy retry-mechanism (if needed), and you avoid the hassle of dealing with multi-threading. Leverage multiple Cognitive Services resources to get around the 10 TPS limit. Alternatively, open a support request and ask for an increased throughput limit. With this information, you should be easily able to analyze vast amounts of documents in no time! Lastly, as Form Recognizer uses Read API under the hood, we can probably use the same strategy when recognizing forms!\n","date":"17 November 2021","permalink":"/posts/azure-read-api-for-processing-many-documents-at-scale/","section":"Posts","summary":"Introduction # The Azure Read API allows you to perform OCR on scanned documents of all kinds.","title":"Using Azure Read API for processing many documents at scale"},{"content":" Introduction # Azure offers a rich set of pre-trained AI models called Cognitive Services which can help you solving a large variety of tasks. For example, services like OCR (Optical Character Recognition), form recognition or Speech-to-Text enable you to automate otherwise labor-intensive business processes.\nLet\u0026rsquo;s take invoice processing as an example. Historically, this has been performed manually and the turnaround time was probably a few hours or even a few days. It was highly asynchronous and it was \u0026ldquo;clear\u0026rdquo; that you had to wait. As we start automating this use case using e.g., Azure Form Recognizer, we can make this process not only significantly faster, but we can make it real-time (synchronous). But what does real-time really mean? 1 second? 5 seconds? 1 minute?\nIf the user is e.g., uploading a document in an app, how long can we have the user wait for the processing? I personally believe it should be either really fast (less than a few seconds), or it should be asynchronous. So if we want to make it fast, how fast can we make it? Cloud hosted APIs might show larger variance in terms of processing times, so does it make sense to self-host if supported? This could potentially give faster and more predictable response times. Let\u0026rsquo;s find out if this is really the case!\nService vs. Self-hosted # For figuring out if it really makes sense to self-host one of the Cognitive Services, we will take the Read, Form Recognizer Invoice and Speech-to-Text APIs as examples. These API are often used for automating a large variety of business processes, such as OCR, invoice processing or call center transcription. All APIs can be consumed as a service in Azure (hosted by Microsoft) or self-hosted as a Docker container (user is responsible for hosting it). So, which one is faster?\nTest Results # All the APIs we have tested are asynchronous, as they might take a few seconds to reply. Therefore, we tested with the following methodology:\nCall API to perform the task (POST) Query until task was finished successfully (GET), with a wait of 10ms between each check Wait for 1 second (probably not needed, but let\u0026rsquo;s avoid running into the rate limit at any cost) Repeat 100 times Read API # For this test, we used a 1600×1200 pixel PNG image (100KB) and we ran it through the Read API for 100 times. We ran these tests from a F16sv2 instance inside Azure, which hosted the Read API container with the recommended resource configuration (8 cores, 24GB of memory). Here are the results, compared to the Azure hosted version:\nHosting Type Azure hosted Container hosted Average processing time 1.257s 1.029s Variance of processing time 0.128 0.003 Minimum processing time 0.852s 0.940s Maximum processing time 3.409s 1.187s Overall, we can see that the self-hosted version is ~20% faster and the variance is ~40x lower. We\u0026rsquo;ve ran this test once in the morning and once in the afternoon (Azure region was West Europe) and observed similar results for both tests.\nIn conclusion, for the Read API we can observe that:\nThe container hosted version is slightly faster and has lower variance, i.e. it is more deterministic in terms of processing time per document (good) At the same time, the container hosted version does not need to handle the vast request amount of requests the hosted version processes every second Hence, it does not have to deal with spikes (at least not in our test) – this obviously explains the lower variance Overall, the average processing time per document is fairly similar, the min/max time are also in a similar ballpark, so there is no big advantage of using the one over the other. However, if your data can\u0026rsquo;t go to the cloud, running the container-hosted version is definitely a big plus point!\nForm Recognizer Invoice API # Next, let\u0026rsquo;s see how the Form Recognizer Invoice API compares for the hosted vs container version. For this, we used a 750×1000 pixel large invoice document (100KB). We ran the required containers on a F32sv2 instance with the recommended settings of:\nLayout container – 8 cores and 24GB of memory (required by the invoice container) Invoice container – 8 cores and 8GB of memory Here are the results after applying the same testing methodology as for the Read API:\nHosting Type Azure hosted Container hosted Average processing time 2.721s 5.527s Variance of processing time 0.457 0.239 Minimum processing time 1.731s 5.084s Maximum processing time 5.318s 6.925s Most notably, the container-hosted version is around 2x slower than the Azure hosted. Wow! This is surprising, given the high resource requirements. Again, processing time variance is lower and minimum and maximum processing time are closer together. This aligns with the results we saw for the Read API. So in summary, unless you want to process data that is not allowed to travel to Azure, relying on the hosted version is just fine.\nSpeech-to-Text Batch Transcription API # For Speech-to-Text Batch Transcription, we\u0026rsquo;ve tested with a single Speech-to-Text container running with various settings. To enable batch transcription, we ran it alongside with the batch transcription container in daemon mode on a F16sv2. We compared this with the average processing time of the hosted batch transcription service in Azure.\nHosting Type Azure hosted Container hosted (4 cores, 4GB of memory) Container hosted (8 cores, 8GB of memory) Processing duration 2x real-time 2x real-time ~3.2x real-time Since the performance looked pretty comparable during my testing, I choose not to publish detailed results. However, especially for transcription of long audio files (e.g., call center recordings), it is important that we can either:\nscale out a self-hosted deployment for transcribing many files in parallel or increase container resources to get a x-fold real-time speed for transcription (or a combination of both) In this case, doubling the resources sped up the transcription by +50%. In this case, it would be more economical to scale out to multiple containers. Again, unless you need to rely on a self-hosted container for data privacy reasons (e.g., transcribing audio containing PII data), there is little value of using the self-hosted version.\nSummary # Overall, the primary reason why Cognitive Services exist in form of containers is to enable scenarios where data privacy is important. Those containers allow to process sensitive data on-premises or on approved cloud providers.\nHowever, our findings show that from a performance perspective the Azure hosted version performs superior and offers much easier access to scale. While the variance in processing time varies a bit, the worst and best-case processing times where all within the same ballpark. Except for extremely time sensitive applications, this probably does not justify the additional effort/cost that is required to host the containers.\n","date":"21 September 2021","permalink":"/posts/azure-cognitive-services-processing-time-comparison/","section":"Posts","summary":"Introduction # Azure offers a rich set of pre-trained AI models called Cognitive Services which can help you solving a large variety of tasks.","title":"Azure Cognitive Services Containers processing time comparison"},{"content":"This is a quick post for showing how to call Azure Machine Learning Pipelines from Azure Data Factory. This includes passing data dynamically into the Machine Learning Pipeline using DataPath.\n##Pipeline Creation\nFirst, let’s create an AzureML Pipeline that we can use for this example. Please note that this code is syntactically correct, but probably won’t run unless you adapt a few parameters, e.g., change the environment, adapt the data path, add a training script, etc.\nimport os import azureml.core from azureml.core import Workspace, Experiment, Dataset, RunConfiguration, Environment from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter from azureml.pipeline.steps import PythonScriptStep from azureml.data.dataset_consumption_config import DatasetConsumptionConfig from azureml.data.datapath import DataPath, DataPathComputeBinding from azureml.pipeline.core import PublishedPipeline, PipelineEndpoint # Connect to workspace ws = Workspace.from_config() # Get default datastore default_datastore = ws.get_default_datastore() # Define default DataPath for training data input and make it configurable via PipelineParameter data_path = DataPath(datastore=default_datastore, path_on_datastore=\u0026#39;training_data/\u0026#39;) datapath_parameter = PipelineParameter(name=\u0026#34;training_data_path\u0026#34;, default_value=data_path) datapath_input = (datapath_parameter, DataPathComputeBinding(mode=\u0026#39;download\u0026#39;)) # Configure runtime environment for our pipeline using AzureML Environment runconfig = RunConfiguration() runconfig.environment = Environment.get(workspace=ws, name=\u0026#39;training-env\u0026#39;) train_step = PythonScriptStep(name=\u0026#34;train-step\u0026#34;, source_directory=\u0026#34;./\u0026#34;, script_name=\u0026#39;train.py\u0026#39;, arguments=[\u0026#39;--data-path\u0026#39;, datapath_input], inputs=[datapath_input], runconfig=runconfig, compute_target=\u0026#39;cpu-cluster\u0026#39;, allow_reuse=False) steps = [train_step] # Create pipeline pipeline = Pipeline(workspace=ws, steps=steps) pipeline.validate() # Publish pipeline to AzureML published_pipeline = pipeline.publish(\u0026#39;prepare-training-pipeline-datapath\u0026#39;) # Publish pipeline to PipelineEndpoint (optional, but recommended when using the pipeline with Azure Data Factory) endpoint_name = \u0026#39;training-pipeline-endpoint\u0026#39; try: print(f\u0026#39;Pipeline Endpoint with name {endpoint_name} already exists, will add pipeline to it\u0026#39;) pipeline_endpoint = PipelineEndpoint.get(workspace=ws, name=endpoint_name) pipeline_endpoint.add_default(published_pipeline) except Exception: print(f\u0026#39;Will create Pipeline Endpoint with name {endpoint_name}\u0026#39;) pipeline_endpoint = PipelineEndpoint.publish(workspace=ws, name=endpoint_name, pipeline=published_pipeline, description=\u0026#34;New Training Pipeline Endpoint\u0026#34;) Most notably, we publish the pipeline as a PublishedPipeline and then add it to a PipelineEndpoint. A PipelineEndpoint acts as a \u0026ldquo;router\u0026rdquo; for multiple PublishedPipelines, and presents a static URL to its callers. As we re-run this code, it’ll just add our new pipeline behind the current endpoint and sets it as the new default.\nFurthermore, we are using DataPath and PipelineParameter to make the data input dynamic. DataPath allows us to specify an arbitrary path on a datastore as an input, and PipelineParameter allows to dynamically pass in the DataPath when invoking the pipeline.\nIn the next step, we’ll call the PipelineEndpoint from Azure Data Factory.\nSetup in Data Factory # In Data Factory, first create a Linked Service to your Azure Machine Learning Workspace. Then create a new Pipeline and add the Machine Learning Execute Pipeline activity.\nCreating a new ADF Pipeline Next, we can configure the Machine Learning component:\nConfiguring our ADF Pipeline From the workspace, we can first select the pipeline we would like to execute. For this, we select our newly created PiplineEndpoint as it allows swapping out the active AzureML Pipeline in the backend – without touching Azure Data Factory. Under Experiment name, we pass in the name under which the pipeline should be executed in AzureML. Lastly, we need to pass in the DataPath via a Data path assignment. For this, we need to put the name of the pipeline parameter(s) for the DataPath in the big text box, then click the small down arrow left to it and add:\nDataStoreName: point to your AzureML Datastore name RelativePath: point to your path inside the Datastore In this example, training_data_path was defined in our code in line 18 (datapath_parameter = PipelineParameter(name=\u0026quot;training_data_path\u0026quot;, default_value=data_path)).\nFinally, we can publish the ADF pipeline, and run it using Add trigger, then select Trigger now. Once it ran, we should see the results in our experiment in Azure Machine Learning Studio:\nSuccessful Azure Machine Learning Pipeline run Looks good! We can see that the experiment was named properly and that the data was correctly pulled from what we set in Azure Data Factory.\nHope this quick tip was helpful!\n","date":"23 July 2021","permalink":"/posts/azure-machine-learning-pipelines-azure-data-factory-datapath/","section":"Posts","summary":"This is a quick post for showing how to call Azure Machine Learning Pipelines from Azure Data Factory.","title":"Invoking Azure Machine Learning Pipelines from Azure Data Factory using DataPath"},{"content":"Introduction # This post is a quick tip, showing how you can automatically enforce an Init Script during Azure Machine Learning Compute Instance provisioning. This ensures that even when the user did not specify a script, a default script is always being executed.\nFor more details on the init script capabilities, have a look at the documentation.\nInstructions # Firstly, create your desired init script – in our example, we\u0026rsquo;ll just use a simple example:\n#!/bin/bash echo \u0026#34;Hello World\u0026#34; Then base64-encode the script and replace the value in line 26 with your encoded script:\n{ \u0026#34;mode\u0026#34;: \u0026#34;All\u0026#34;, \u0026#34;policyRule\u0026#34;: { \u0026#34;if\u0026#34;: { \u0026#34;allOf\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;type\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;Microsoft.MachineLearningServices/workspaces/computes\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.MachineLearningServices/workspaces/computes/computeType\u0026#34;, \u0026#34;in\u0026#34;: [ \u0026#34;ComputeInstance\u0026#34; ] } ] }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;append\u0026#34;, \u0026#34;details\u0026#34;: [{ \u0026#34;field\u0026#34;: \u0026#34;Microsoft.MachineLearningServices/workspaces/computes/setupScripts.scripts.creationScript.scriptSource\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;inline\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.MachineLearningServices/workspaces/computes/setupScripts.scripts.creationScript.scriptData\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;IyEvYmluL2Jhc2gKCmVjaG8gIkhlbGxvIFdvcmxkIg==\u0026#34; } ] } } } Next, create a new Policy definition in Azure Policy:\nCreate a new Policy definition You\u0026rsquo;ll need to define in which subscription the definition should live in, give it a name and a description and then finally paste the policy JSON into the Policy Rule. Then hit Save.\nOur Policy definition Now that we have a Policy, we can create an assignment. This will apply the policy to Azure resources. Inside Azure Policy, navigate to Assignments and select Assign policy.\nCreating our assignment Then define the scope of the assignment (which subscriptions it should affect), select our Policy definition and hit Create.\nAsssigning our policy That\u0026rsquo;s it, our policy is live!\nMaking sure it works # Lastly, go to Azure Machine Learning Studio and provision a new Compute Instance without selecting an init script. Once the instance has been provisioned, open the instance details and you should see the stdout under the Logs tab.\nOur init script successfully executed Hope this helps!\nHappy instance creating!\n","date":"19 July 2021","permalink":"/posts/enforcing-init-scripts-on-azure-machine-learning-compute-instances/","section":"Posts","summary":"Introduction # This post is a quick tip, showing how you can automatically enforce an Init Script during Azure Machine Learning Compute Instance provisioning.","title":"Enforcing Init Scripts on Azure Machine Learning Compute Instances"},{"content":"Introduction # This post outlines how you can mount a Dataset to a Compute Instance in Azure Machine. This can help exploring file-based datasets in Jupyter, especially for large datasets where download to the disk of the Compute Instance is impractical. Furthermore, this method can also help during exploration phase, where you probably want to read only a subset of the data.\nPrerequisites # All we need to get started is a Workspace with a file-based Dataset, as well as a Compute Instance. Im testing this on a STANDARD_DS3_V2 instance in West Europe.\nDataset in Azure Machine Learning Mounting a Dataset to a Compute Instance # Lets start up Jupyter or JupyterLab on the Compute Instance. You can execute the following code to mount the dataset to the machine, access the data, and then later unmount it:\nimport os import pandas as pd from azureml.core import Workspace, Dataset # Connect to Workspace and reference Dataset ws = Workspace.from_config() dataset = ws.datasets[\u0026#34;german-credit-train-tutorial\u0026#34;] # Create mountcontext and mount the dataset mount_ctx = dataset.mount() mount_ctx.start() # Get the mount point dataset_mount_folder = mount_ctx.mount_point print(dataset_mount_folder) # List the files in the mount point files = os.listdir(dataset_mount_folder) print(files) # Read some data df = pd.read_csv(os.path.join(dataset_mount_folder, \u0026#39;german_credit_data.csv\u0026#39;)) # Do some more stuff with the data.... # Unmount the dataset from the instance mount_ctx.stop() If you want to mount the dataset to a specific folder, you can also specify the mount path, e.g., mount(mount_point='/mnt/dataset1'). In this case, the path already needs to exist. See the API documentation for more details.\nMounting a Dataset in Juypter In case you forget to stop the mount context (i.e., unmounting it), no worries! You can also do it from the command line later:\nazureuser@clemens-vm:/$ mount | grep /tmp _DPrepFuse on /tmp/tmp89tgbd31 type fuse (rw,nosuid,nodev,relatime,user_id=1001,group_id=1002) azureuser@clemens-vm:/$ sudo umount /tmp/tmp89tgbd31 azureuser@clemens-vm:/$ mount | grep /tmp Restarting the Compute Instance will also remove the mount. Azure Machine Learning uses fuse to mount the Storage Account. Therefore, there is no drawback on the Storage Account in case you forget to unmount it. The dataset is mounted as read-only, there you cannot cause any inconsistencies anyway.\nPerformance # In my quick test, I was using a 10 GB file in Blob Storage and just read it into the Compute Instance:\n$ dd if=test_10gb.tmp of=/dev/null bs=64k 163840+0 records in 163840+0 records out 10737418240 bytes (11 GB, 10 GiB) copied, 89.567 s, 120 MB/s The results are very much in line with the expected performance for reading a single file in Blob (Standard tier). Typically, we should see around ~80-120MB/s per file (sometimes even a bit more). Reading files in parallel, leveraging Premium Blob, ADLSg2, or using a larger Compute Instance size, etc. could obviously improve performance even more.\nSummary # Mounting a Dataset to a Compute Instance in Azure Machine Learning is easy and can dramatically help during data exploration and when dealing with large datasets.\nStay safe and let me know if you have any questions!\n","date":"7 December 2020","permalink":"/posts/mount-datasets-compute-instance-azure-machine-learning/","section":"Posts","summary":"Introduction # This post outlines how you can mount a Dataset to a Compute Instance in Azure Machine.","title":"Mounting Datasets to a Compute Instance in Azure Machine Learning"},{"content":"Hello World!\n","date":"1 January 0001","permalink":"/about/","section":"Clemens Siebler's Blog","summary":"Hello World!","title":"About"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"}]