<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><title>Understanding Azure OpenAI's x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers &#183; Clemens Siebler's Blog</title>
<meta name=title content="Understanding Azure OpenAI's x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers &#183; Clemens Siebler's Blog"><script type=text/javascript src=/js/appearance.min.74ad8406faea02f3e186ba5126249aaeed9073629e04b05037b903396b188724.js integrity="sha256-dK2EBvrqAvPhhrpRJiSaru2Qc2KeBLBQN7kDOWsYhyQ="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.7c1e6d40b23627ab31090b2d8fcdf80392861650296ac97e1d0d4d184dee1930.css integrity="sha256-fB5tQLI2J6sxCQstj834A5KGFlApasl+HQ1NGE3uGTA="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.3e80d0528c59616e7de9b0ca9316d9afd314b49ed9e5e6b88873731486ad67ee.js integrity="sha256-PoDQUoxZYW596bDKkxbZr9MUtJ7Z5ea4iHNzFIatZ+4=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        Introduction #Azure OpenAI has (silently) introduced two new headers for token and request tracking (x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests), which help to get a feeling of how many requests and tokens an API caller is still allowed to perform.
      
    "><link rel=canonical href=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/"><meta property="og:site_name" content="Clemens Siebler's Blog"><meta property="og:title" content="Understanding Azure OpenAI's x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers"><meta property="og:description" content="Introduction #Azure OpenAI has (silently) introduced two new headers for token and request tracking (x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests), which help to get a feeling of how many requests and tokens an API caller is still allowed to perform."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-05T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding Azure OpenAI's x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers"><meta name=twitter:description content="Introduction #Azure OpenAI has (silently) introduced two new headers for token and request tracking (x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests), which help to get a feeling of how many requests and tokens an API caller is still allowed to perform."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Understanding Azure OpenAI\u0027s x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers","headline":"Understanding Azure OpenAI\u0027s x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers","abstract":"Introduction #Azure OpenAI has (silently) introduced two new headers for token and request tracking (x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests), which help to get a feeling of how many requests and tokens an API caller is still allowed to perform.","inLanguage":"en","url":"https:\/\/clemenssiebler.com\/posts\/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers\/","author":{"@type":"Person","name":""},"copyrightYear":"2024","dateCreated":"2024-06-05T00:00:00\u002b00:00","datePublished":"2024-06-05T00:00:00\u002b00:00","dateModified":"2024-06-05T00:00:00\u002b00:00","mainEntityOfPage":"true","wordCount":"1292"}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-HB3D5YJ128"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-HB3D5YJ128")}</script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 sm:px-14 md:px-24 lg:px-32 dark:bg-neutral-800 dark:text-neutral"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 print:hidden sm:py-10 dark:text-neutral"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Clemens Siebler&rsquo;s Blog</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Posts</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/talks/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Talks</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Understanding Azure OpenAI's x-ratelimit-remaining-tokens and x-ratelimit-remaining-requests headers</h1><div class="mb-12 mt-8 text-base text-neutral-500 print:hidden dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime="2024-06-05 00:00:00 +0000 UTC">5 June 2024</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">7 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 print:hidden lg:sticky lg:top-10"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#new-headers>New Headers</a></li><li><a href=#deep-dive-into-x-ratelimit-remaining-tokens>Deep dive into <code>x-ratelimit-remaining-tokens</code></a></li><li><a href=#deep-dive-into-x-ratelimit-remaining-requests>Deep dive into <code>x-ratelimit-remaining-requests</code></a></li><li><a href=#summary>Summary</a></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><h2 id=introduction class="relative group">Introduction <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#introduction aria-label=Anchor>#</a></span></h2><p>Azure OpenAI has (silently) introduced two new headers for token and request tracking (<code>x-ratelimit-remaining-tokens</code> and <code>x-ratelimit-remaining-requests</code>), which help to get a feeling of how many requests and tokens an API caller is still allowed to perform. This post explains how we can interpret them, as they are not as straight forward to understand as one might think or hope.</p><h2 id=new-headers class="relative group">New Headers <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#new-headers aria-label=Anchor>#</a></span></h2><p>The two new headers we&rsquo;ll discuss here are returned for each API call (at least for the models that support the headers) and are the following:</p><ul><li><code>x-ratelimit-remaining-tokens</code> - Returns how many tokens the caller can still consume without getting a <code>429</code> back</li><li><code>x-ratelimit-remaining-requests</code> - Returns how many inference requests the caller can still perform without getting a <code>429</code> back</li></ul><p>So let&rsquo;s do a quick example:</p><p><strong>Model deployment:</strong></p><ul><li>Model: gpt-4-turbo-2024-04-09</li><li>Configured token quota: 20k TPM (Tokens/min)</li><li>Request quota: 120 RPM (Req/min) - Azure OpenAI gives 6 RPM per 1k TPM</li><li>Dynamic quota: Disabled</li></ul><p>So let&rsquo;s run a quick test with:</p><ul><li>Prompt tokens: 100</li><li><code>max_tokens</code>: 25</li></ul><p>Once the API request comes back, the usage is reported correctly (same results as when counting it beforehand using <code>tiktoken</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl>  <span class=s2>&#34;usage&#34;</span><span class=err>:</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;completion_tokens&#34;</span><span class=p>:</span> <span class=mi>25</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;prompt_tokens&#34;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;total_tokens&#34;</span><span class=p>:</span> <span class=mi>125</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>and if we look at our headers, we see the following:</p><ul><li><code>x-ratelimit-remaining-tokens</code>: 19913</li><li><code>x-ratelimit-remaining-requests</code>: 19</li></ul><p>Tokens look kind of right (even though it should be 19875), but why is the request limit only 19? Shouldn&rsquo;t we have 119 left? Let&rsquo;s dive into it!</p><h2 id=deep-dive-into-x-ratelimit-remaining-tokens class="relative group">Deep dive into <code>x-ratelimit-remaining-tokens</code> <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deep-dive-into-x-ratelimit-remaining-tokens aria-label=Anchor>#</a></span></h2><p>To figure out how tokens are measured, let&rsquo;s run a more sophisticated test with the following properties:</p><p><strong>Model deployment:</strong></p><ul><li>Model: gpt-35-turbo-1106</li><li>Configured token quota: 10k TPM</li><li>Request quota: 60 RPM</li><li>Dynamic quota: Disabled</li></ul><p><strong>Call properties:</strong></p><ul><li>100 Input tokens</li><li>2000 max_tokens (the generation will stop well before, but we need to &ldquo;eat&rdquo; up token quota to hit the limit)</li></ul><p>In this case, we calculate the actual token cost that was deducted from our quota by subtracting it from our known quota (10k) or the last reported remaining tokens from the API response. This means we run single-threaded, no calls in parallel, and wait until each call is done. Let&rsquo;s run it for a bit over a minute:</p><pre tabindex=0><code>Time 0.0s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 7939 / Tokens used: 100+73=173 / Actual token cost: 2061
Time 1.9s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 5878 / Tokens used: 100+74=174 / Actual token cost: 2061
Time 3.6s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 3815 / Tokens used: 100+71=171 / Actual token cost: 2063
Time 5.4s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 1753 / Tokens used: 100+74=174 / Actual token cost: 2062
Time 7.8s / Model gpt-35-turbo-1106 / HTTP 429
...many more 429 errors...
Time 59.6s / Model gpt-35-turbo-1106 / HTTP 429
Time 60.2s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 1752 / Tokens used: 100+74=174 / Actual token cost: 1
Time 62.2s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 1752 / Tokens used: 100+73=173 / Actual token cost: 0
Time 64.5s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 1752 / Tokens used: 100+74=174 / Actual token cost: 0
Time 66.7s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining tokens: 1753 / Tokens used: 100+67=167 / Actual token cost: -1
Time 68.6s / Model gpt-35-turbo-1106 / HTTP 429
...many more 429 errors...
</code></pre><p>Firstly, we can see that we can get four initial calls through, which was expected. Each call requires 100+2000=2100 tokens in total and we need to stay below 10k tokens per minute. Furthermore we see the remaining tokens decrease until we have less available than our requested payload cost. We also clearly see that the high <code>max_token</code> settings removes valuable tokens from our quota, despite the response only being ~75 tokens (as shared in earlier posts, always keep <code>max_tokens</code> as low as possible).</p><p>In addition, we see that tokens start to get &ldquo;refilled&rdquo; exactly 60 seconds after they were consumed. They do not get refilled at once, but rather on a rolling basis (otherwise the first call after the 60 second mark would have had a cost of ~-8400). This means Azure OpenAI uses a rolling window of 60 seconds to manage the TPM quota. As an example, if we right now place a call that uses 5000 tokens, we&rsquo;d get back 5000 tokens of quota 60 seconds later. This aligns with the documentation (<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota?tabs=rest#understanding-rate-limits" target=_blank rel=noreferrer>Understanding rate limits</a>), where it is stated that the quota management happens on 10 or 60 seconds windows (depends on the model). This approach makes sense, as it allows for large API calls to pass through.</p><p><figure><img src=/images/aoai_tpm_refill.png alt="Azure OpenAI&amp;rsquo;s token quota refill logic" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Azure OpenAI&rsquo;s token quota refill logic</figcaption></figure></p><p>However, it is unclear to me why the actual token cost is ~2061 and not 2100 and I could not figure out why this is happening. However, it always seems to be below the actual used token amount.</p><h2 id=deep-dive-into-x-ratelimit-remaining-requests class="relative group">Deep dive into <code>x-ratelimit-remaining-requests</code> <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deep-dive-into-x-ratelimit-remaining-requests aria-label=Anchor>#</a></span></h2><p>Let&rsquo;s repeat the same test to understand how the remaining requests header works, but let&rsquo;s reduce the TPM so we can test the behavior with fewer API calls:</p><p><strong>Model deployment:</strong></p><ul><li>Model: gpt-35-turbo-1106</li><li>Configured token quota: 2k TPM</li><li>Request quota: 12 RPM</li><li>Dynamic quota: Disabled</li></ul><p><strong>Call properties:</strong></p><ul><li>100 Input tokens</li><li>10 max_tokens (to not hit any TPM quota limit)</li></ul><pre tabindex=0><code>Time 0.0s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 1 / Remaining tokens: 1838
Time 2.1s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 1674
Time 3.9s / Model gpt-35-turbo-1106 / HTTP 429
...more 429 errors...
Time 10.0s / Model gpt-35-turbo-1106 / HTTP 429
Time 10.6s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 1511
Time 12.6s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 1349
Time 14.3s / Model gpt-35-turbo-1106 / HTTP 429
...more 429 errors...
Time 20.5s / Model gpt-35-turbo-1106 / HTTP 429
Time 21.1s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 1187
Time 22.9s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 1024
Time 26.4s / Model gpt-35-turbo-1106 / HTTP 429
...more 429 errors...
Time 30.7s / Model gpt-35-turbo-1106 / HTTP 429
Time 31.4s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 861
Time 33.1s / Model gpt-35-turbo-1106 / HTTP 200 / Remaining requests: 0 / Remaining tokens: 699
Time 34.8s / Model gpt-35-turbo-1106 / HTTP 429
...more 429 errors...
</code></pre><p>This looks very different from what we were expecting after the first test! Only two calls pass through - how can this be? Well, if we look at the full log, it becomes clear: the RPM limit is not enforced on a minute window, but rather on a 10 second window. This means, if we made a call right now, we&rsquo;d get back a <code>+1</code> &ldquo;call refill&rdquo; 10 seconds later. This also explains why we only get 1/6th of the full minute quota that the UI and documentation shows us. Initially, this caused a lot of confusion for me personally (&ldquo;Why can&rsquo;t I push more more calls through!!!&rdquo;), but made sense once I understood how it works.</p><p><figure><img src=/images/aoai_rpm_refill.png alt="Azure OpenAI&amp;rsquo;s request quota refill logic" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Azure OpenAI&rsquo;s request quota refill logic</figcaption></figure></p><h2 id=summary class="relative group">Summary <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#summary aria-label=Anchor>#</a></span></h2><p>Using the <code>x-ratelimit-remaining-tokens</code> and <code>x-ratelimit-remaining-requests</code> headers in Azure OpenAI can be a useful tool to estimate how many calls we can still make before e.g., needing to switch to a different model deployment or resource. However, it is crucial to understand on which time-window those metrics operate and how they get &ldquo;refilled&rdquo;. Hence, in summary:</p><ul><li>Token quota gets refilled 60 seconds after a call has been accepted (by the amount of tokens deducted)</li><li>Request quota gets refilled 10 seconds after a call has been accepted</li></ul><p>With this, it is easy to optimize throughput or run batch jobs more efficiently.</p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=flex><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;quote=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Share on Facebook" aria-label="Share on Facebook" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;text=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Tweet on Twitter" aria-label="Tweet on Twitter" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;description=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Pin on Pinterest" aria-label="Pin on Pinterest" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M496 256c0 137-111 248-248 248-25.6.0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8.0 128.7-68.8 128.7-154.3.0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1.0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6.0-54.7 41.4-107.6 112-107.6 60.9.0 103.6 41.5 103.6 100.9.0 67.1-33.9 113.6-78 113.6-24.3.0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6.0-19-10.2-34.9-31.4-34.9-24.9.0-44.9 25.7-44.9 60.2.0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9.0 361.1.0 256 0 119 111 8 248 8s248 111 248 248z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;resubmit=true&amp;title=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Submit to Reddit" aria-label="Submit to Reddit" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;title=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Share on LinkedIn" aria-label="Share on LinkedIn" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://clemenssiebler.com/posts/understanding-azure-openai-x-ratelimit-remaining-tokens-x-ratelimit-remaining-requests-headers/&amp;subject=Understanding%20Azure%20OpenAI%27s%20x-ratelimit-remaining-tokens%20and%20x-ratelimit-remaining-requests%20headers" title="Send via email" aria-label="Send via email" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/smart-loadbalancing-for-azure-openai-with-api-management/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Smart Load-Balancing for Azure OpenAI with Azure API Management</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-12-20 00:00:00 +0000 UTC">20 December 2023</time>
</span></span></a></span><span></span></div></div></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer></div></body></html>