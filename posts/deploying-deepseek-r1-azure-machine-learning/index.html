<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><title>Securely deploying Deepseek R1 on Azure Machine Learning &#183; Clemens Siebler's Blog</title>
<meta name=title content="Securely deploying Deepseek R1 on Azure Machine Learning &#183; Clemens Siebler's Blog"><script type=text/javascript src=/js/appearance.min.74ad8406faea02f3e186ba5126249aaeed9073629e04b05037b903396b188724.js integrity="sha256-dK2EBvrqAvPhhrpRJiSaru2Qc2KeBLBQN7kDOWsYhyQ="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.7c1e6d40b23627ab31090b2d8fcdf80392861650296ac97e1d0d4d184dee1930.css integrity="sha256-fB5tQLI2J6sxCQstj834A5KGFlApasl+HQ1NGE3uGTA="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.3e80d0528c59616e7de9b0ca9316d9afd314b49ed9e5e6b88873731486ad67ee.js integrity="sha256-PoDQUoxZYW596bDKkxbZr9MUtJ7Z5ea4iHNzFIatZ+4=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        
      
    "><link rel=canonical href=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/"><meta property="og:site_name" content="Clemens Siebler's Blog"><meta property="og:title" content="Securely deploying Deepseek R1 on Azure Machine Learning"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-28T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Securely deploying Deepseek R1 on Azure Machine Learning"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Securely deploying Deepseek R1 on Azure Machine Learning","headline":"Securely deploying Deepseek R1 on Azure Machine Learning","inLanguage":"en","url":"https:\/\/clemenssiebler.com\/posts\/deploying-deepseek-r1-azure-machine-learning\/","author":{"@type":"Person","name":""},"copyrightYear":"2025","dateCreated":"2025-01-28T00:00:00\u002b00:00","datePublished":"2025-01-28T00:00:00\u002b00:00","dateModified":"2025-01-28T00:00:00\u002b00:00","mainEntityOfPage":"true","wordCount":"1115"}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-HB3D5YJ128"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-HB3D5YJ128")}</script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 sm:px-14 md:px-24 lg:px-32 dark:bg-neutral-800 dark:text-neutral"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 print:hidden sm:py-10 dark:text-neutral"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Clemens Siebler&rsquo;s Blog</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Posts</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/talks/ title=Talks><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Talks</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title=About><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Securely deploying Deepseek R1 on Azure Machine Learning</h1><div class="mb-12 mt-8 text-base text-neutral-500 print:hidden dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime="2025-01-28 00:00:00 +0000 UTC">28 January 2025</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">6 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 print:hidden lg:sticky lg:top-10"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction-to-vllm>Introduction to vLLM</a></li><li><a href=#managed-online-endpoints-in-azure-machine-learning>Managed Online Endpoints in Azure Machine Learning</a></li></ul><ul><li><a href=#step-1-create-a-custom-environment-for-vllm-on-azureml>Step 1: Create a custom Environment for vLLM on AzureML</a><ul><li><a href=#step-2-deploy-the-azureml-managed-online-endpoint>Step 2: Deploy the AzureML Managed Online Endpoint</a></li></ul></li><li><a href=#step-2-testing-the-deployment>Step 2: Testing the deployment</a><ul><li><a href=#step-4---testing-the-deployment>Step 4 - Testing the deployment</a></li></ul></li><li><a href=#autoscaling-our-deepseek-r1-deployment>Autoscaling our Deepseek R1 deployment</a></li><li><a href=#summary>Summary</a></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><h1 id=introduction class="relative group">Introduction <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#introduction aria-label=Anchor>#</a></span></h1><p>In this post, we&rsquo;ll explain how to deploy <a href=https://huggingface.co/deepseek-ai/DeepSeek-R1 target=_blank rel=noreferrer>Deepseek R1</a> via vLLMs using Azure Machine Learning&rsquo;s Managed Online Endpoints for efficient, scalable, and secure real-time inference. This has the benefit that the model is running within your own Azure subscription and you&rsquo;re in full control of what is happening to your data. For example, this allows to deploy <code>R1</code> within a region of the US or EU, e.g., <code>eastus2</code>, <code>swedencentral</code> or others.</p><p>In detail, we&rsquo;ll be deploying <a href=https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B target=_blank rel=noreferrer>DeepSeek-R1-Distill-Llama-8B</a>, which is based off <code>Llama-3.1-8B</code>.</p><p><figure><img src=/images/deepseek-logo.png alt="Deepseek Logo" class="mx-auto my-0 rounded-md"></figure></p><h1 id=tools-used class="relative group">Tools used <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tools-used aria-label=Anchor>#</a></span></h1><p>To deploy <code>R1</code>, we&rsquo;ll be using:</p><ul><li>vLLM</li><li>Managed Online Endpoints in Azure Machine Learning</li></ul><p>Here&rsquo;s a short summary of what those two components do:</p><h2 id=introduction-to-vllm class="relative group">Introduction to vLLM <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#introduction-to-vllm aria-label=Anchor>#</a></span></h2><p><a href=https://github.com/vllm-project/vllm target=_blank rel=noreferrer>vLLM</a> is a high-throughput and memory-efficient inference and serving engine designed for large language models (LLMs). It optimizes the serving and execution of LLMs by utilizing advanced memory management techniques, such as PagedAttention, which efficiently manages attention key and value memory. This allows for continuous batching of incoming requests and fast model execution, making vLLM a powerful tool for deploying and serving LLMs at scale.</p><p>vLLM supports seamless integration with popular Hugging Face models and offers various decoding algorithms, including parallel sampling and beam search. It also supports tensor parallelism and pipeline parallelism for distributed inference, making it a flexible and easy-to-use solution for LLM inference (see <a href=https://docs.vllm.ai/en/latest/ target=_blank rel=noreferrer>full docs</a>).</p><h2 id=managed-online-endpoints-in-azure-machine-learning class="relative group">Managed Online Endpoints in Azure Machine Learning <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#managed-online-endpoints-in-azure-machine-learning aria-label=Anchor>#</a></span></h2><p>Managed Online Endpoints in Azure Machine Learning provide a streamlined and scalable way to deploy machine learning models for real-time inference. These endpoints handle the complexities of serving, scaling, securing, and monitoring models, allowing us to focus on building and improving your models without worrying about infrastructure management.</p><h1 id=deepseek-r1-model-deployment class="relative group">Deepseek R1 model deployment <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deepseek-r1-model-deployment aria-label=Anchor>#</a></span></h1><p>Let&rsquo;s go through deploying <code>R1</code> on Azure Machine Learning&rsquo;s Managed Online Endpoints. For this, we&rsquo;ll use a custom Dockerfile and configuration files to set up the deployment. As a model, we&rsquo;ll be using <a href=https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B target=_blank rel=noreferrer>deepseek-ai/DeepSeek-R1-Distill-Llama-8B</a> on a single <code>Standard_NC24ads_A100_v4</code> instance.</p><h2 id=step-1-create-a-custom-environment-for-vllm-on-azureml class="relative group">Step 1: Create a custom Environment for vLLM on AzureML <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#step-1-create-a-custom-environment-for-vllm-on-azureml aria-label=Anchor>#</a></span></h2><p>First, we create a <code>Dockerfile</code> to define the environment for our model. For this, we&rsquo;ll be using vllm&rsquo;s base container that has all the dependencies and drivers included:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>FROM</span><span class=s> vllm/vllm-openai:latest</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> MODEL_NAME deepseek-ai/DeepSeek-R1-Distill-Llama-8B<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENTRYPOINT</span> python3 -m vllm.entrypoints.openai.api_server --model <span class=nv>$MODEL_NAME</span> <span class=nv>$VLLM_ARGS</span><span class=err>
</span></span></span></code></pre></div><p>The idea here is that we can pass a model name via an ENV variable, so that we can easily define which model we want to deploy during deployment time.</p><p>Next, we log into our Azure Machine Learning workspace:</p><pre tabindex=0><code class=language-cli data-lang=cli>az account set --subscription &lt;subscription ID&gt;
az configure --defaults workspace=&lt;Azure Machine Learning workspace name&gt; group=&lt;resource group&gt;
</code></pre><p>Now, we create an <code>environment.yml</code> file to specify the environment settings:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>$schema</span><span class=p>:</span><span class=w> </span><span class=l>https://azuremlschemas.azureedge.net/latest/environment.schema.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>r1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>dockerfile_path</span><span class=p>:</span><span class=w> </span><span class=l>Dockerfile</span><span class=w>
</span></span></span></code></pre></div><p>Then let&rsquo;s build the environment:</p><pre tabindex=0><code class=language-cli data-lang=cli>az ml environment create -f environment.yml
</code></pre><h3 id=step-2-deploy-the-azureml-managed-online-endpoint class="relative group">Step 2: Deploy the AzureML Managed Online Endpoint <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#step-2-deploy-the-azureml-managed-online-endpoint aria-label=Anchor>#</a></span></h3><p>Time for deployment, so let&rsquo;s first create an <code>endpoint.yml</code> file to define the Managed Online Endpoint:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>$schema</span><span class=p>:</span><span class=w> </span><span class=l>https://azuremlsdk2.blob.core.windows.net/latest/managedOnlineEndpoint.schema.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>r1-prod</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>auth_mode</span><span class=p>:</span><span class=w> </span><span class=l>key</span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s create it:</p><pre tabindex=0><code class=language-cli data-lang=cli>az ml online-endpoint create -f endpoint.yml
</code></pre><p>For the next step, we&rsquo;ll need the address of the Docker image address we created. We can quickly get it from AzureML Studio -> Environments -> r1:</p><p><figure><img src=/images/r1_docker_image_link.png alt="Docker Image address" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Docker Image address</figcaption></figure></p><p>Finally, we create a <code>deployment.yml</code> file to configure the deployment settings and deploy our desired model from HuggingFace via vLLM:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>$schema</span><span class=p>:</span><span class=w> </span><span class=l>https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>current</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>endpoint_name</span><span class=p>:</span><span class=w> </span><span class=l>r1-prod</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>environment_variables</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>MODEL_NAME</span><span class=p>:</span><span class=w> </span><span class=l>deepseek-ai/DeepSeek-R1-Distill-Llama-8B</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>VLLM_ARGS</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;--max-num-seqs 16 --enforce-eager&#34;</span><span class=w> </span><span class=c># optional args for vLLM runtime</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>xxxxxx.azurecr.io/azureml/azureml_xxxxxxxx</span><span class=w> </span><span class=c># paste Docker image address here</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>inference_config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>liveness_route</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/health</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>readiness_route</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/health</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>scoring_route</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>instance_type</span><span class=p>:</span><span class=w> </span><span class=l>Standard_NC24ads_A100_v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>instance_count</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>request_settings</span><span class=p>:</span><span class=w> </span><span class=c># This section is optional, yet important for optimizing throughput</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max_concurrent_requests_per_instance</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>request_timeout_ms</span><span class=p>:</span><span class=w> </span><span class=m>10000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>liveness_probe</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>initial_delay</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>period</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>success_threshold</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>failure_threshold</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>readiness_probe</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>initial_delay</span><span class=p>:</span><span class=w> </span><span class=m>120</span><span class=w> </span><span class=c># wait for 120s before we start probing, so the model can load peacefully</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>period</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>success_threshold</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>failure_threshold</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span></code></pre></div><p>A full explanation of the parameters can be found in my prior post <a href=https://clemenssiebler.com/posts/vllm-on-azure-machine-learning-managed-online-endpoints-deployment/ target=_blank rel=noreferrer>Deploying vLLM models on Azure Machine Learning with Managed Online Endpoints
</a>.</p><p>Lastly, we can deploy the r1 model:</p><pre tabindex=0><code class=language-cli data-lang=cli>az ml online-deployment create -f deployment.yml --all-traffic
</code></pre><p>By following these steps, we have deployed a HuggingFace model on Azure Machine Learning’s Managed Online Endpoints, ensuring efficient and scalable real-time inference. Time to test it!</p><h2 id=step-2-testing-the-deployment class="relative group">Step 2: Testing the deployment <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#step-2-testing-the-deployment aria-label=Anchor>#</a></span></h2><p>First, let&rsquo;s get the endpoint&rsquo;s scoring uri and the api keys:</p><pre tabindex=0><code class=language-cli data-lang=cli>az ml online-endpoint show -n r1-prod
az ml online-endpoint get-credentials -n r1-prod
</code></pre><p>For completion models, we can then call the endpoint using this Python code snippet:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://r1-prod.polandcentral.inference.ml.azure.com/v1/completions&#34;</span>
</span></span><span class=line><span class=cl><span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Content-Type&#34;</span><span class=p>:</span> <span class=s2>&#34;application/json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Authorization&#34;</span><span class=p>:</span> <span class=s2>&#34;Bearer xxxxxxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=s2>&#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>		<span class=s2>&#34;messages&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>			<span class=p>{</span>
</span></span><span class=line><span class=cl>				<span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>				<span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;What is Deepseek r1?&#34;</span>
</span></span><span class=line><span class=cl>			<span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span> <span class=n>json</span><span class=o>=</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>())</span>
</span></span></code></pre></div><p>Response:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;id&#34;</span><span class=p>:</span><span class=s2>&#34;chatcmpl-305d162f-80d2-4e92-bb61-0cc114a5cada&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;object&#34;</span><span class=p>:</span><span class=s2>&#34;chat.completion&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;created&#34;</span><span class=p>:</span><span class=mi>1738052045</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;model&#34;</span><span class=p>:</span><span class=s2>&#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;choices&#34;</span><span class=p>:[</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;index&#34;</span><span class=p>:</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;message&#34;</span><span class=p>:{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;role&#34;</span><span class=p>:</span><span class=s2>&#34;assistant&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;content&#34;</span><span class=p>:</span><span class=s2>&#34;&lt;think&gt;\n\n&lt;/think&gt;\n\nDeepSeek-R1 is an AI assistant developed by the Chinese company DeepSeek. It is designed to provide helpful and accurate information on a wide range of topics, and it is constantly updated with new data and strengthened in understanding and response capabilities. If you have any questions or need assistance, DeepSeek-R1 is here to help!&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;tool_calls&#34;</span><span class=p>:[</span>
</span></span><span class=line><span class=cl>               
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>         <span class=p>},</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;logprobs&#34;</span><span class=p>:</span><span class=s2>&#34;None&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;finish_reason&#34;</span><span class=p>:</span><span class=s2>&#34;stop&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;stop_reason&#34;</span><span class=p>:</span><span class=s2>&#34;None&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>   <span class=p>],</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;usage&#34;</span><span class=p>:{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;prompt_tokens&#34;</span><span class=p>:</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;total_tokens&#34;</span><span class=p>:</span><span class=mi>81</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;completion_tokens&#34;</span><span class=p>:</span><span class=mi>71</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;prompt_tokens_details&#34;</span><span class=p>:</span><span class=s2>&#34;None&#34;</span>
</span></span><span class=line><span class=cl>   <span class=p>},</span>
</span></span><span class=line><span class=cl>   <span class=nt>&#34;prompt_logprobs&#34;</span><span class=p>:</span><span class=s2>&#34;None&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Works!</p><h3 id=step-4---testing-the-deployment class="relative group">Step 4 - Testing the deployment <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#step-4---testing-the-deployment aria-label=Anchor>#</a></span></h3><p>Again, let&rsquo;s get the endpoints scoring uri and the api keys:</p><pre tabindex=0><code class=language-cli data-lang=cli>az ml online-endpoint show -n r1-prod
az ml online-endpoint get-credentials -n r1-prod
</code></pre><p>We can then call the endpoint using this Python code snippet:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://r1-prod.polandcentral.inference.ml.azure.com/v1/completions&#34;</span>
</span></span><span class=line><span class=cl><span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Content-Type&#34;</span><span class=p>:</span> <span class=s2>&#34;application/json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Authorization&#34;</span><span class=p>:</span> <span class=s2>&#34;Bearer xxxxxxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=s2>&#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>		<span class=s2>&#34;messages&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;What is the capital of France?&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span> <span class=n>json</span><span class=o>=</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>())</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json></code></pre></div><h2 id=autoscaling-our-deepseek-r1-deployment class="relative group">Autoscaling our Deepseek R1 deployment <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#autoscaling-our-deepseek-r1-deployment aria-label=Anchor>#</a></span></h2><p>Autoscaling Managed Online Endpoint deployments in Azure Machine Learning allows us to dynamically adjust the number of instances allocated to our endpoints based on real-time metrics and schedules. This ensures that our application can handle varying loads efficiently without manual intervention. By integrating with Azure Monitor, you can set up rules to scale out when the CPU or GPU utilization exceeds a certain threshold or scale in during off-peak hours. For detailed guidance on configuring autoscaling, you can refer to the <a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-autoscale-endpoints?view=azureml-api-2&amp;tabs=cli" target=_blank rel=noreferrer>official documentation</a>.</p><h2 id=summary class="relative group">Summary <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#summary aria-label=Anchor>#</a></span></h2><p>In this post, we&rsquo;ve discussed how to deploy the 8bn parameter version of Deepseek&rsquo;s R1 model to Azure Machine Learning&rsquo;s Managed Online Endpoints for efficient real-time inference. This allowed us to use R1 in a secure, private environment where we have full control over the data and full model ownership. Furthermore, this allowed us to run the model in an Azure region of our choice, e.g., in a US- or EU-based Azure data center.</p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=flex><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;quote=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Share on Facebook" aria-label="Share on Facebook" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;text=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Tweet on Twitter" aria-label="Tweet on Twitter" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;description=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Pin on Pinterest" aria-label="Pin on Pinterest" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M496 256c0 137-111 248-248 248-25.6.0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8.0 128.7-68.8 128.7-154.3.0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1.0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6.0-54.7 41.4-107.6 112-107.6 60.9.0 103.6 41.5 103.6 100.9.0 67.1-33.9 113.6-78 113.6-24.3.0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6.0-19-10.2-34.9-31.4-34.9-24.9.0-44.9 25.7-44.9 60.2.0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9.0 361.1.0 256 0 119 111 8 248 8s248 111 248 248z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;resubmit=true&amp;title=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Submit to Reddit" aria-label="Submit to Reddit" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;title=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Share on LinkedIn" aria-label="Share on LinkedIn" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://clemenssiebler.com/posts/deploying-deepseek-r1-azure-machine-learning/&amp;subject=Securely%20deploying%20Deepseek%20R1%20on%20Azure%20Machine%20Learning" title="Send via email" aria-label="Send via email" target=_blank rel="noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/azure-openai-gpt4o-audio-api-cost-analysis/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The new gpt-4o-audio-preview in Azure OpenAI is awesome! But how much will it actually cost me?</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2025-01-24 00:00:00 +0000 UTC">24 January 2025</time>
</span></span></a></span><span></span></div></div></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".prose img"));images.forEach(e=>{mediumZoom(e,{margin:5,scrollOffset:40,container:null,template:null})})</script></footer></div></body></html>